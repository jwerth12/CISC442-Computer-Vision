{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k4lVQ5iPw-hC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the CIFAR100 dataset\n",
        "data_transforms = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(\n",
        "      mean = [0.485, 0.456, 0.406],   # Usimg mean and std dev of ImageNet\n",
        "      std = [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=data_transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOrBfOJWxK3k",
        "outputId": "71b6a63c-3440-4647-bac3-3b3c9ae0abda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 48958494.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our own CNN\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # 3 convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "\n",
        "        # 1 max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 100)  # 100 classes in CIFAR-100\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# call what we just defined to create a model\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "A6G9SKo9xexY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our loss and optimizer similar to part 1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "RSEHzm6Gy8Jd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the CNN\n",
        "for epoch in range(30):  # use 30 epochs\n",
        "    print(\"Epoch\", epoch+1, \"/30\")\n",
        "    total_loss = 0.0    # track our loss as we train to make sure we are training effectively\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # tracking loss for testing purposes\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(trainloader)}\")\n",
        "\n",
        "torch.save(model.state_dict(), 'trained_CNN.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3t8zahPzMjr",
        "outputId": "801ab004-2e68-4f22-d6b0-277a9f7aad2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 /30\n",
            "Epoch 1, Loss: 0.9157492529477\n",
            "Epoch 2 /30\n",
            "Epoch 2, Loss: 0.7951360586125528\n",
            "Epoch 3 /30\n",
            "Epoch 3, Loss: 0.6885850172289802\n",
            "Epoch 4 /30\n",
            "Epoch 4, Loss: 0.5783343438030509\n",
            "Epoch 5 /30\n",
            "Epoch 5, Loss: 0.48796228681455184\n",
            "Epoch 6 /30\n",
            "Epoch 6, Loss: 0.39647048868029316\n",
            "Epoch 7 /30\n",
            "Epoch 7, Loss: 0.33479650185236237\n",
            "Epoch 8 /30\n",
            "Epoch 8, Loss: 0.2718682424415408\n",
            "Epoch 9 /30\n",
            "Epoch 9, Loss: 0.23422965934723997\n",
            "Epoch 10 /30\n",
            "Epoch 10, Loss: 0.19208670676688253\n",
            "Epoch 11 /30\n",
            "Epoch 11, Loss: 0.167403253471798\n",
            "Epoch 12 /30\n",
            "Epoch 12, Loss: 0.1394134173312646\n",
            "Epoch 13 /30\n",
            "Epoch 13, Loss: 0.12454799231132278\n",
            "Epoch 14 /30\n",
            "Epoch 14, Loss: 0.10817771648054424\n",
            "Epoch 15 /30\n",
            "Epoch 15, Loss: 0.0961601715475378\n",
            "Epoch 16 /30\n",
            "Epoch 16, Loss: 0.06880717251635611\n",
            "Epoch 17 /30\n",
            "Epoch 17, Loss: 0.06478357745829941\n",
            "Epoch 18 /30\n",
            "Epoch 18, Loss: 0.04308659883568545\n",
            "Epoch 19 /30\n",
            "Epoch 19, Loss: 0.03821507364343566\n",
            "Epoch 20 /30\n",
            "Epoch 20, Loss: 0.0254538741595138\n",
            "Epoch 21 /30\n",
            "Epoch 21, Loss: 0.018709682711802633\n",
            "Epoch 22 /30\n",
            "Epoch 22, Loss: 0.0132712096787508\n",
            "Epoch 23 /30\n",
            "Epoch 23, Loss: 0.011089013279516897\n",
            "Epoch 24 /30\n",
            "Epoch 24, Loss: 0.010521664453954424\n",
            "Epoch 25 /30\n",
            "Epoch 25, Loss: 0.010562814337358027\n",
            "Epoch 26 /30\n",
            "Epoch 26, Loss: 0.009757201448204996\n",
            "Epoch 27 /30\n",
            "Epoch 27, Loss: 0.009020348443560984\n",
            "Epoch 28 /30\n",
            "Epoch 28, Loss: 0.009424955315214744\n",
            "Epoch 29 /30\n",
            "Epoch 29, Loss: 0.00944520557484449\n",
            "Epoch 30 /30\n",
            "Epoch 30, Loss: 0.008821216828572086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model to predict labels for test set and print accuracy\n",
        "testset = datasets.CIFAR100('.', train=False, transform = data_transforms, download=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Move the model to GPU (if available):\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Set model to evaluation / testing mode\n",
        "model.eval()\n",
        "\n",
        "# define vars for accuracy evaluation later\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(test_loader, 0):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    correct += (preds == labels).sum().item()\n",
        "    total += labels.size(0)\n",
        "\n",
        "accuracy = (correct / total) * 100\n",
        "print(accuracy)\n"
      ],
      "metadata": {
        "id": "aTsBxsNDLyrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83152919-6d21-4091-93dc-b20709d26e47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 48704279.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-100-python.tar.gz to .\n",
            "39.92\n"
          ]
        }
      ]
    }
  ]
}